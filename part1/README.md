
In this week, Chapters 1,2 and 3 upto section 3.4 was completed. This contains the introduction to multi armed bandits and Markov's decision process. 

In this part, we will cover multi-armed bandits and markov decision processes.
