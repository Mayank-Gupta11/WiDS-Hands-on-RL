# Part 1

<<<<<<< HEAD:week1/README.md
In this week, Chapters 1,2 and 3 upto section 3.4 was completed. This contains the introduction to multi armed bandits and Markov's decision process. 
=======
In this part, we will cover multi-armed bandits and markov decision processes.
>>>>>>> upstream/main:part1/README.md

Lectures 6 and 8 were covered from [CS747](https://www.cse.iitb.ac.in/~shivaram/teaching/cs747-a2022/index.html)
